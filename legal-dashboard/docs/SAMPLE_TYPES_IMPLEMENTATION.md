# Sample Types Implementation - Complete Guide

**Date**: 2025-10-16
**Status**: ‚úÖ Infrastructure Complete, Ready for Dataset Bootstrap

---

## üéØ What We Accomplished

### Problem Identified
The generator prompt had a **critical misalignment** with the training notebook:

1. **Generator**: Created 4 different sample types (case_analysis, educational, client_interaction, statutory_interpretation) with different answer structures
2. **Training Notebook**: Only formatted samples in ONE way (IRAC format)
3. **Self-Validation**: Always checked for IRAC structure, even for non-IRAC sample types

This meant:
- Generated samples had contradictory instructions
- Training data wouldn't teach the model about different answer styles
- The model couldn't learn versatile response formats

### Solution Implemented (Fix 2 + Fix 3)

#### ‚úÖ Fix 1: Dynamic Generator Validation (`services/generation_service.py`)

**Changes Made**:
1. **Dynamic structure validation** (lines 188-203):
   - Creates sample_type-specific validation messages
   - `case_analysis` ‚Üí validates IRAC structure
   - `educational` ‚Üí validates Definition ‚Üí Legal Basis ‚Üí Key Elements structure
   - `client_interaction` ‚Üí validates Understanding ‚Üí Position ‚Üí Options structure
   - `statutory_interpretation` ‚Üí validates Statutory Text ‚Üí Purpose ‚Üí Interpretation structure

2. **Dynamic reasoning guidance** (line 243):
   - Tailors reasoning instructions to sample type
   - IRAC types get "Demonstrate IRAC progression"
   - Educational types get "Show progression from definition to application"
   - Client types get "Show client-focused reasoning"
   - Statutory types get "Show progression from statutory text to application"

3. **Sample type field** (lines 310, 355-357):
   - Added `sample_type` to JSON output format
   - Ensures sample_type is always present in generated samples
   - Falls back to provided sample_type if LLM doesn't include it

**Result**: Generator now creates coherent, type-specific prompts with matching validation

#### ‚úÖ Fix 2: Training Notebook Sample Type Support

**File**: `sft-law-book-simple-multigpu.ipynb` ‚Üí Cell 7

**Changes Made**:
1. **Sample type detection**:
   ```python
   sample_type = sample.get('sample_type', 'case_analysis')
   ```
   - Defaults to 'case_analysis' for backward compatibility with existing data

2. **Sample type in training format**:
   ```python
   ### Sample Type: {sample_type}
   ```
   - Model sees which type each sample is

3. **Type-specific hints in answer section**:
   ```python
   type_hints = {
       'case_analysis': '(IRAC: Issue ‚Üí Rule ‚Üí Application ‚Üí Conclusion)',
       'educational': '(Teaching: Definition ‚Üí Legal Basis ‚Üí Key Elements ‚Üí Examples)',
       'client_interaction': '(Client Advice: Understanding ‚Üí Position ‚Üí Options ‚Üí Recommendation)',
       'statutory_interpretation': '(Statutory: Text ‚Üí Purpose ‚Üí Interpretation ‚Üí Case Law)'
   }

   ### Answer {hint}:
   ```
   - Helps model learn structure for each type

4. **Updated Gradio UI** (Cell 16):
   - Added sample type selector (radio buttons)
   - Inference function passes sample_type to prompt
   - Model can generate different answer styles at inference time

**Result**: Training data now teaches the model to recognize and use 4 different answer structures

---

## üìä Testing Results

Ran `test_sample_types_alignment.py` to verify all 4 sample types:

| Sample Type | Status | Reason |
|------------|--------|--------|
| case_analysis | ‚úÖ PASS | Dataset has IRAC examples, model generates valid JSON |
| educational | ‚ùå FAIL | No training examples yet, JSON parse errors |
| client_interaction | ‚ùå FAIL | No training examples yet, JSON parse errors |
| statutory_interpretation | ‚ùå FAIL | No training examples yet, JSON parse errors |

**This is EXPECTED behavior!** The model can only generate what it's been trained on.

---

## üöÄ Next Steps: Bootstrap the Dataset

### Why Bootstrap?
Currently, your dataset has ~2,054 samples, all in `case_analysis` format (IRAC). To train the model on multiple sample types, you need examples of each type.

### Option 1: Manual Bootstrap (High Quality, Slow)
Use the UI to generate samples manually:

1. Start the apps:
   ```bash
   cd legal-dashboard
   python3 api_server.py  # Terminal 1
   npm run dev            # Terminal 2
   ```

2. Open http://localhost:5173 ‚Üí Generation Tab

3. Generate 50+ samples for each type:
   - Select sample_type from dropdown
   - Choose different topics/difficulties
   - Click "Generate Single Sample"
   - Review quality before accepting

4. Target distribution:
   - case_analysis: 40% (maintain as primary format)
   - educational: 30% (teaching concepts)
   - client_interaction: 20% (practical advice)
   - statutory_interpretation: 10% (legislation focus)

**Estimated time**: 4-6 hours for 200 high-quality samples

### Option 2: Automated Bootstrap (Fast, Needs Review)
Use the bootstrap script I created:

```bash
cd legal-dashboard
python3 bootstrap_sample_types.py
```

This will:
1. Generate 10 samples of each type automatically
2. Save to `train.parquet`
3. Show final sample type distribution

**Estimated time**: 5-10 minutes

**‚ö†Ô∏è Important**: Review generated samples! The model hasn't been trained on these types yet, so quality may vary. Delete low-quality samples before training.

### Option 3: Hybrid Approach (Recommended)
1. Run `bootstrap_sample_types.py` to quickly generate 40 seed samples (10 per type)
2. Manually review and fix any issues
3. Generate 50-100 more samples manually using the UI
4. Target: 150-200 total samples across all types

**Estimated time**: 1-2 hours

---

## üìà Training the Multi-Format Model

Once you have 150+ samples with good type distribution:

### 1. Push Updated Dataset to HuggingFace

```bash
# From the React UI
Open http://localhost:5173 ‚Üí Dataset Tab ‚Üí Push to HuggingFace
# OR via Python
import polars as pl
from huggingface_hub import HfApi

df = pl.read_parquet("legal-dashboard/train.parquet")
df.write_parquet("train_multi_format.parquet")

api = HfApi()
api.upload_file(
    path_or_fileobj="train_multi_format.parquet",
    path_in_repo="train.parquet",
    repo_id="rzeraat/law",
    repo_type="dataset",
    token="YOUR_HF_TOKEN"
)
```

### 2. Run the Training Notebook

The notebook is **already updated** to handle sample types!

Just run:
```python
# In Google Colab or Jupyter
# Open: /Users/rezazeraat/Desktop/Data/sft-law-book-simple-multigpu.ipynb
# Run all cells
```

Key changes already in place:
- Cell 7: `format_sample()` now handles all 4 sample types
- Cell 16: Gradio UI lets you choose sample type at inference

### 3. Expected Training Outcomes

After training on multi-format data:

**Before** (current model):
- User: "What is consideration?"
- Model: **ISSUE**: The question asks about consideration. **RULE**: ...
- ‚ùå Always uses IRAC, even when inappropriate

**After** (multi-format model):
- User: "What is consideration?" + sample_type="educational"
- Model: **DEFINITION**: Consideration is a fundamental concept... **LEGAL BASIS**: Established in Currie v Misa [1875]... **KEY ELEMENTS**: 1. Must have value, 2. Must move from promisee... **EXAMPLES**: ...
- ‚úÖ Adapts answer style to sample type

---

## üîß What Changed in Your Codebase

### Modified Files

1. **`services/generation_service.py`** (lines 188-243, 310, 355-357)
   - Dynamic structure validation based on sample_type
   - Dynamic reasoning guidance
   - sample_type field added to generated samples

2. **`sft-law-book-simple-multigpu.ipynb`** (Cells 7, 16)
   - Cell 7: `format_sample()` with sample type support
   - Cell 16: Gradio UI with sample type selector

### New Files Created

1. **`test_sample_types_alignment.py`**
   - Test script to verify generator/training alignment
   - Tests all 4 sample types
   - Shows how samples look in training format

2. **`bootstrap_sample_types.py`**
   - Automated bootstrap script
   - Generates 40 seed samples (10 per type)
   - Saves directly to train.parquet

3. **`SAMPLE_TYPES_IMPLEMENTATION.md`** (this file)
   - Complete guide to what we did and why
   - Next steps for bootstrapping
   - Training instructions

---

## üéì Understanding Sample Types

### case_analysis (IRAC)
**Use when**: Problem-solving scenarios requiring legal analysis

**Structure**:
- **ISSUE**: What's the legal question?
- **RULE**: What law applies?
- **APPLICATION**: How does the law apply to the facts?
- **CONCLUSION**: What's the answer?

**Example**: "My client signed a contract under duress. Can they void it?"

### educational (Teaching)
**Use when**: Explaining legal concepts, doctrines, or principles

**Structure**:
- **DEFINITION**: What is the concept?
- **LEGAL BASIS**: What's the statutory/case law foundation?
- **KEY ELEMENTS**: What are the essential components?
- **EXAMPLES**: How does it work in practice?
- **DISTINCTIONS**: What's commonly confused?

**Example**: "What is promissory estoppel?"

### client_interaction (Practical Advice)
**Use when**: Lawyer-client communication requiring actionable guidance

**Structure**:
- **UNDERSTANDING**: Acknowledge client's situation
- **LEGAL POSITION**: Explain relevant law (client-friendly)
- **OPTIONS**: Present available courses of action
- **RECOMMENDATION**: Advise best approach
- **NEXT STEPS**: Provide clear action items

**Example**: "My company is facing a breach of contract claim. What should I do?"

### statutory_interpretation (Legislative Analysis)
**Use when**: Questions about statutes, regulations, or their application

**Structure**:
- **STATUTORY TEXT**: Quote relevant provisions
- **PURPOSE**: Explain legislative intent
- **INTERPRETATION**: Break down key terms
- **CASE LAW**: Show judicial interpretation
- **APPLICATION**: Demonstrate practical application

**Example**: "What does Section 172 of the Companies Act 2006 require?"

---

## üí° Best Practices

### When Generating New Sample Types

1. **Be explicit in questions**:
   - ‚ùå "Tell me about directors' duties"
   - ‚úÖ "What are directors' duties?" (educational)
   - ‚úÖ "My client is a director. What duties do they have?" (client_interaction)

2. **Match difficulty to sample type**:
   - Basic educational: Simple concept explanations
   - Expert case_analysis: Complex multi-issue problems
   - Intermediate client_interaction: Common client scenarios

3. **Verify structure in answers**:
   - Check that IRAC samples follow Issue ‚Üí Rule ‚Üí Application ‚Üí Conclusion
   - Check that educational samples have Definition ‚Üí Legal Basis ‚Üí Key Elements ‚Üí Examples

4. **Use real case citations for all types**:
   - Educational samples need foundational cases (e.g., Donoghue v Stevenson for negligence)
   - Client interaction samples need practical precedents
   - Statutory samples need interpretation cases

### Dataset Balance Recommendations

Based on practical legal work distribution:

- **40% case_analysis**: Primary format for problem-solving (maintain as core)
- **30% educational**: Teaching concepts (important for junior lawyers/students)
- **20% client_interaction**: Practical advice (real-world applicability)
- **10% statutory_interpretation**: Legislative analysis (specialized but essential)

Total target: **500-1000 samples per type** for robust multi-format model

---

## ‚úÖ Summary

**What's Done**:
- ‚úÖ Generator creates sample-type-specific prompts
- ‚úÖ Training notebook formats samples by type
- ‚úÖ Validation is dynamic based on sample type
- ‚úÖ Gradio UI supports sample type selection
- ‚úÖ Infrastructure is fully aligned

**What's Next**:
1. Bootstrap dataset with new sample types (use `bootstrap_sample_types.py`)
2. Review and refine generated samples
3. Push updated dataset to HuggingFace
4. Re-train model with multi-format data
5. Test inference with different sample types

**Expected Outcome**:
A legal AI that can adapt its answer style to the user's needs:
- Formal IRAC analysis for legal professionals
- Clear teaching format for students
- Practical client-friendly advice for consultations
- Detailed statutory analysis for legislative questions

---

**Questions?** Review the test scripts:
- `test_sample_types_alignment.py` - Shows generator/training alignment
- `bootstrap_sample_types.py` - Automated seed sample generation

**Ready to proceed?** Run the bootstrap script and start training! üöÄ
